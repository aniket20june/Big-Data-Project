{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recognition_Minor1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniket20june/Big-Data-Project/blob/main/Recognition_Minor1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOI4rlrgxPI-"
      },
      "source": [
        "## Outline\n",
        "\n",
        "\n",
        "1. Data set and task\n",
        "2. Data processing XML files\n",
        "3. Why we need encoder decoder architecture\n",
        "4. Basic GRU based encoder decoder\n",
        "5. Adding attention\n",
        "6. Evaluation\n",
        "7. Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GqTjeV47m4B"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpuvHS0mxwCd"
      },
      "source": [
        "## Data Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYrAa5laSptM"
      },
      "source": [
        "### Alphabets Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a04ZKx7Sh-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656fb997-e806-43bd-c61b-75e5e6c24cb7"
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPSZsy1kXd9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e731b1f8-07c2-483f-e987-0b9f2225e025"
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSw1SMZmx9A3"
      },
      "source": [
        "### Helper functions for data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcS6ByndOxrC"
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob3F9Dh4PChB"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGSeoMGg0FTy"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FCCi-SerZS-"
      },
      "source": [
        "train_data = TransliterationDataLoader('train_transliteration.xml')\n",
        "test_data = TransliterationDataLoader('test_transliteration.xml')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l-iaCVdx5Ez"
      },
      "source": [
        "### Basic Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjY06ghEx76b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc0fbe24-b48f-4bde-8e4f-50d83d3a7570"
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20641\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "SALISH - सालिश\n",
            "KURDE - कुरडे\n",
            "HASEEN - हसीन\n",
            "INNISFALLEN - इनिसफॉलन\n",
            "MADAN - मदन\n",
            "FRANCISCO - फ्रान्सिस्को\n",
            "AZAMGARH - आजमगढ़\n",
            "MRAGANAYANEE - मृगनयनी\n",
            "WINONA - विनोना\n",
            "BANWET - बनवेट\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpDP1_KYZIkv"
      },
      "source": [
        "### Encoding the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE3at5C7Sy5F"
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yE3jToOrfzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66f6daa-f0f1-4e16-f796-760ef1a7d3bd"
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROEBUCK tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMcDjIberhc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e555e9f4-2463-4b72-b5f8-331130467fee"
      },
      "source": [
        "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_gt)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "रोबक tensor([[49],\n",
            "        [76],\n",
            "        [45],\n",
            "        [22],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrC3tSnm4rUk"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4OgdZ_DVVC5"
      },
      "source": [
        "### Encoder-Decoder (using GRU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w8ffT3w4lkK"
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        out, hidden = self.encoder_rnn_cell(input)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder input', input.shape)\n",
        "            print('Encoder output', out.shape)\n",
        "            print('Encoder hidden', hidden.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        outputs = []\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder input', decoder_input.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "            \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "            one_hot.zero_()\n",
        "            one_hot.scatter_(2, max_idx, 1)\n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cra9toTiOoPm"
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyFcUMiuSbK4"
      },
      "source": [
        "def infer(net, word, char_limit, device = 'cpu'):\r\n",
        "\r\n",
        "    input = word_rep(word, eng_alpha2index, device)\r\n",
        "\r\n",
        "    return net(input, char_limit)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4zaJq2pOrM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f80559-1135-4dd6-a131-a503caa35929"
      },
      "source": [
        "out = infer(net, \"BAHADUR\", 30)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder input torch.Size([8, 1, 27])\n",
            "Encoder output torch.Size([8, 1, 256])\n",
            "Encoder hidden torch.Size([1, 1, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 129])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_pdzBmQOsjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "968feaf9-caea-48cd-b707-b828d1e0e661"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ऎ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ऎ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ऎ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ऎ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ऎ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ऎ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ऎ\n",
            "torch.Size([1, 129]) श\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEg49N9e7oTY"
      },
      "source": [
        "### Encoder-Decoder with Attention \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z-1QDAz8F_d"
      },
      "source": [
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        \n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
        "            \n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "            \n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "            \n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "                \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "                \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMD3zjdJO0Oj"
      },
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoiQwbntO5UH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d50f29-91a7-47be-a1f5-033ac8821d74"
      },
      "source": [
        "out = infer(net_attn, 'INDIA', 30)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output torch.Size([6, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder intermediate input torch.Size([1, 1, 129])\n",
            "U * Encoder output torch.Size([6, 256])\n",
            "W * Decoder state torch.Size([6, 256])\n",
            "V torch.Size([6, 1])\n",
            "Attn torch.Size([1, 6])\n",
            "Attn LC torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 512])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9WSPgzlO6k8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902e3681-3a3c-4cf0-c32d-e0ffc3440c75"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) क\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) झ\n",
            "torch.Size([1, 129]) क\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) झ\n",
            "torch.Size([1, 129]) क\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) झ\n",
            "torch.Size([1, 129]) क\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) झ\n",
            "torch.Size([1, 129]) क\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) झ\n",
            "torch.Size([1, 129]) क\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) झ\n",
            "torch.Size([1, 129]) क\n",
            "torch.Size([1, 129]) ॽ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyE2tSnmAW6x"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H893cimDtTUE"
      },
      "source": [
        "### Core Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m804jsH7AXSV"
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-eZaBxstWz9"
      },
      "source": [
        "### Training Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjto129ssrpr"
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZY6RvqLtdX8"
      },
      "source": [
        "### Training without Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oQ3ZIWvtjfN"
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6LjVKQfoVMU"
      },
      "source": [
        "train_setup(net, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM1Tj20omMi1"
      },
      "source": [
        "### Training with Attention "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxFLBqW1Ip4v"
      },
      "source": [
        "net_att = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdRpJUXNIwuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "f6a6423a-adaa-44b5-caa7-a29c4c814322"
      },
      "source": [
        "loss_history = train_setup(net_att, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1969 Loss 0.1484350711107254\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05F1-FwX6YVZ"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3TWC7zhAn3z"
      },
      "source": [
        "def test(net, word, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net, word, 30, device)\n",
        "    hindi_output = ''\n",
        "    for out in outputs:\n",
        "        val, indices = out.topk(1)\n",
        "        index = indices.tolist()[0][0]\n",
        "        if index == 0:\n",
        "            break\n",
        "        hindi_char = hindi_alphabets[index+1]\n",
        "        hindi_output += hindi_char\n",
        "    print(word + ' - ' + hindi_output)\n",
        "    return hindi_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT8bibYl7CgX"
      },
      "source": [
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
        "        outputs = infer(net, eng, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy1bQiORAs5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c981272d-d162-4490-850f-edd96664434f"
      },
      "source": [
        "accuracy = calc_accuracy(net) * 100\n",
        "accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Accuracy w/o attention ', accuracy)\n",
        "print('Acurracy with attention', accuracy_attn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy w/o attention  22.70685897435895\n",
            "Acurracy with attention 18.36795288045286\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}